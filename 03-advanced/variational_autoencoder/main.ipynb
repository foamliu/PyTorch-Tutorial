{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\foamliu.fareast\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "c:\\users\\foamliu.fareast\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\torch\\nn\\functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 37079.0781, KL Div: 3871.6084\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29926.7949, KL Div: 954.2637\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 28103.2969, KL Div: 1145.8278\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 26669.2852, KL Div: 694.5894\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 25759.6875, KL Div: 745.4025\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 24631.3672, KL Div: 915.0233\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 25130.7383, KL Div: 914.4310\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 23800.0410, KL Div: 954.4619\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 24106.8301, KL Div: 1122.5366\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 22789.3613, KL Div: 1320.8110\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 22088.5840, KL Div: 1353.2518\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 21427.8555, KL Div: 1439.4177\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 20197.9727, KL Div: 1664.0808\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19475.9492, KL Div: 1727.8218\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 18794.9766, KL Div: 1800.4059\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 18410.7168, KL Div: 1770.8337\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18414.0957, KL Div: 1900.4402\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 18239.1211, KL Div: 1919.1064\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 16997.9805, KL Div: 1988.2385\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 18051.5859, KL Div: 1905.5962\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 17518.6250, KL Div: 1994.4476\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17245.7734, KL Div: 2105.7593\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 16758.3906, KL Div: 2190.4524\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 17187.2949, KL Div: 2216.0710\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 16883.1504, KL Div: 2203.4290\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16301.0830, KL Div: 2161.8447\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 16216.0410, KL Div: 2086.7195\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 16725.5391, KL Div: 2370.1772\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 14850.6953, KL Div: 2317.4089\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15358.2119, KL Div: 2343.3379\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 16051.0400, KL Div: 2257.5249\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 15824.4922, KL Div: 2290.2266\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 15208.9365, KL Div: 2460.6477\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 15466.0449, KL Div: 2523.2446\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 14978.4092, KL Div: 2615.6143\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 14927.4502, KL Div: 2313.9626\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 15105.0957, KL Div: 2500.4297\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14412.1270, KL Div: 2458.0750\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 13440.7910, KL Div: 2379.6182\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14811.9219, KL Div: 2599.3496\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 13977.4668, KL Div: 2515.9358\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14116.0195, KL Div: 2600.9673\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 14163.7393, KL Div: 2529.0728\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 14311.7314, KL Div: 2560.2891\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 14073.3154, KL Div: 2580.2039\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 13857.4697, KL Div: 2608.2485\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 13666.2900, KL Div: 2644.1064\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 12856.3291, KL Div: 2679.1296\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 14255.9102, KL Div: 2732.5232\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13626.1543, KL Div: 2747.7607\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13172.7656, KL Div: 2676.1758\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13678.2607, KL Div: 2662.1880\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13091.6230, KL Div: 2872.8738\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 12989.6143, KL Div: 2734.2478\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13218.8086, KL Div: 2712.0420\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13483.9609, KL Div: 2859.8066\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 12594.8438, KL Div: 2737.3789\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 13125.5225, KL Div: 2651.5708\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 13222.4902, KL Div: 2863.9932\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 13672.3691, KL Div: 2787.5215\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 12307.5391, KL Div: 2797.3450\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 12808.6523, KL Div: 2642.2839\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 11981.5029, KL Div: 2680.7085\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 12910.6650, KL Div: 2866.6565\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 12725.2051, KL Div: 2889.6345\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12890.3896, KL Div: 2860.0461\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12242.2148, KL Div: 2762.9663\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 13019.4238, KL Div: 2902.6018\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12794.2656, KL Div: 2924.5171\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12021.5098, KL Div: 2851.0515\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12582.0469, KL Div: 2977.8774\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12343.3193, KL Div: 2876.6008\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12001.5918, KL Div: 2886.2476\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 11631.4541, KL Div: 2878.2166\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 11993.6602, KL Div: 2898.3525\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12260.1357, KL Div: 2984.8965\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12229.2686, KL Div: 2891.2341\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12037.9980, KL Div: 2846.2773\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12543.0986, KL Div: 2950.1338\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 12487.5742, KL Div: 3036.5144\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 12265.5156, KL Div: 2889.1636\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12206.2773, KL Div: 3085.8740\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12298.2930, KL Div: 2989.3164\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 12221.2930, KL Div: 2962.5762\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12365.8164, KL Div: 2933.3435\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 12512.9443, KL Div: 2939.4341\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 12458.7412, KL Div: 2970.4832\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 11639.3467, KL Div: 3021.6108\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 12762.4688, KL Div: 2920.8198\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 11269.5371, KL Div: 3007.7769\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 12005.7832, KL Div: 2993.8877\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 11487.8955, KL Div: 2895.1287\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 11624.2266, KL Div: 2907.4392\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 12351.2051, KL Div: 3094.2422\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11875.6846, KL Div: 2950.4336\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 11672.1494, KL Div: 3051.8652\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 12157.1455, KL Div: 3032.1462\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11243.9072, KL Div: 2938.1079\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11530.9902, KL Div: 3073.0669\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 12240.7412, KL Div: 3042.1836\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 12031.7480, KL Div: 3098.1523\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11340.5547, KL Div: 3018.7341\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 11403.1465, KL Div: 3153.1260\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11682.2227, KL Div: 2928.0327\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 12038.7344, KL Div: 3050.5493\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11463.2363, KL Div: 2942.5862\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11942.2070, KL Div: 3056.4131\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11230.6758, KL Div: 3084.4250\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11896.5059, KL Div: 3078.2441\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11317.3936, KL Div: 2901.6282\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11604.9072, KL Div: 3076.3677\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11474.4180, KL Div: 3124.0273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/15], Step [210/469], Reconst Loss: 11299.6523, KL Div: 2942.2620\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11406.1777, KL Div: 3020.8474\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11675.7891, KL Div: 3063.2966\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11567.3652, KL Div: 3155.5940\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11369.1729, KL Div: 3072.6624\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 12318.1611, KL Div: 3097.6685\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11274.5605, KL Div: 2928.3696\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11449.5156, KL Div: 3079.3726\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11667.5713, KL Div: 3172.6001\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11331.6562, KL Div: 3055.3020\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11258.3369, KL Div: 2924.6538\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11145.0215, KL Div: 3132.3491\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11869.5176, KL Div: 3156.2590\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11348.5664, KL Div: 3080.4570\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11387.7334, KL Div: 3134.9006\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11256.0879, KL Div: 3099.6704\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11854.9688, KL Div: 3104.2534\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 10997.7910, KL Div: 3080.6714\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11637.1396, KL Div: 3115.2229\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11642.1055, KL Div: 3159.5845\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11570.7461, KL Div: 3190.9082\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11333.9355, KL Div: 2992.4521\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11225.3799, KL Div: 3144.5237\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11840.5732, KL Div: 3077.8774\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11254.0518, KL Div: 3189.4785\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 11222.5557, KL Div: 3018.0496\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11388.6523, KL Div: 3127.0610\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 11060.1719, KL Div: 3083.1172\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 10904.4775, KL Div: 3067.5959\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11485.4648, KL Div: 3182.1460\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11034.9180, KL Div: 3060.1494\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11076.3770, KL Div: 3146.4548\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11916.9092, KL Div: 3166.6790\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11507.6611, KL Div: 3103.4858\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11741.7832, KL Div: 3188.8823\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 11378.4834, KL Div: 3163.1438\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 11141.7881, KL Div: 3138.5679\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 10673.5127, KL Div: 3218.4431\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11202.6357, KL Div: 3061.2817\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 10363.5840, KL Div: 3171.6211\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 11462.3379, KL Div: 3174.6912\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 11019.8809, KL Div: 3018.8000\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 10863.2041, KL Div: 3237.5620\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11013.3789, KL Div: 3043.4060\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 11114.5176, KL Div: 3103.5977\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11207.4824, KL Div: 3126.4851\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 11413.3379, KL Div: 3208.6143\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 11041.9326, KL Div: 3200.7651\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 11704.9219, KL Div: 3107.1252\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 11305.9131, KL Div: 3200.4417\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 11284.5049, KL Div: 3049.0298\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11315.5186, KL Div: 3174.1785\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 11335.7256, KL Div: 3131.9148\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 11820.1113, KL Div: 3200.5288\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10999.1309, KL Div: 3116.5942\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11008.8965, KL Div: 3110.8994\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 11524.8809, KL Div: 3201.6331\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11542.4277, KL Div: 3178.2778\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 11116.8506, KL Div: 3128.4976\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 11179.2061, KL Div: 3209.7383\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 10704.6201, KL Div: 3031.1592\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 11476.9316, KL Div: 3091.1958\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 11609.0449, KL Div: 3309.5957\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 10976.7881, KL Div: 3162.9133\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11428.9990, KL Div: 3184.7178\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 10893.0820, KL Div: 3185.2898\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 10798.4766, KL Div: 3057.3906\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 10906.1484, KL Div: 3275.6714\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 10513.5293, KL Div: 3110.9006\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 10861.1992, KL Div: 3161.8870\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 10472.4834, KL Div: 3100.5891\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 10606.0625, KL Div: 3184.5581\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 10875.2803, KL Div: 3212.3325\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 11163.2334, KL Div: 3250.1284\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 10611.8340, KL Div: 3206.3174\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 11316.4883, KL Div: 3142.0303\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 10513.2275, KL Div: 3258.5371\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 10553.3271, KL Div: 3100.5298\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 10769.5820, KL Div: 3100.2432\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 10870.0176, KL Div: 3278.4387\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 10913.2705, KL Div: 3087.9214\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 11465.7471, KL Div: 3280.2861\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 11037.6250, KL Div: 3169.7827\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 10409.4883, KL Div: 3187.4307\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 10515.5039, KL Div: 3118.1118\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 10580.9814, KL Div: 3244.4221\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 10804.7324, KL Div: 3069.3328\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 10727.8779, KL Div: 3313.0750\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 11045.4814, KL Div: 3190.7341\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 11060.4951, KL Div: 3142.5283\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 10557.2549, KL Div: 3133.5918\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 11101.2012, KL Div: 3135.9680\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 10745.4629, KL Div: 3306.1157\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 10988.6592, KL Div: 3186.8008\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 10475.6201, KL Div: 3268.1226\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 10796.9502, KL Div: 3109.2617\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 10671.5518, KL Div: 3117.9819\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 11163.5674, KL Div: 3174.5911\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 10954.6113, KL Div: 3243.6919\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 10683.6035, KL Div: 3235.2388\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 10868.0781, KL Div: 3057.7822\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 10826.2246, KL Div: 3234.5488\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 11162.4805, KL Div: 3150.0752\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 11298.5117, KL Div: 3256.5393\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 10787.6602, KL Div: 3246.7080\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 10454.3682, KL Div: 3120.5813\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10535.1113, KL Div: 3129.8530\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 10865.7637, KL Div: 3205.9033\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10695.8066, KL Div: 3163.4045\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 10726.2588, KL Div: 3264.9106\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10908.8428, KL Div: 3203.1323\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10970.1133, KL Div: 3231.5620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/15], Step [410/469], Reconst Loss: 11175.7988, KL Div: 3190.4648\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 11042.8350, KL Div: 3219.3569\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 10477.7246, KL Div: 3167.5459\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 10937.5908, KL Div: 3063.1104\n",
      "Epoch[5/15], Step [450/469], Reconst Loss: 10433.0127, KL Div: 3179.4331\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 10567.0195, KL Div: 3307.3638\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10277.8701, KL Div: 3107.6472\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 10736.3896, KL Div: 3215.6562\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10381.4922, KL Div: 3111.1646\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 10541.6162, KL Div: 3251.4485\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 11202.1729, KL Div: 3195.9629\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 11120.1133, KL Div: 3203.3801\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10566.9072, KL Div: 3228.8340\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 11102.8262, KL Div: 3245.1523\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 11169.4990, KL Div: 3133.5981\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 10763.6885, KL Div: 3236.1235\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 11306.1836, KL Div: 3227.3428\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 11016.8945, KL Div: 3261.4453\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10530.3721, KL Div: 3251.6960\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10856.7744, KL Div: 3120.8479\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 10520.6152, KL Div: 3229.6426\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10817.4336, KL Div: 3205.1677\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 10483.9795, KL Div: 3158.4580\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10498.6504, KL Div: 3223.2573\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 10199.0527, KL Div: 3144.4521\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 9913.6318, KL Div: 3146.5461\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10423.1416, KL Div: 3148.7334\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10746.1504, KL Div: 3191.2944\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 11183.3496, KL Div: 3275.1904\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10875.0547, KL Div: 3149.7651\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 10900.8223, KL Div: 3309.8672\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10511.1943, KL Div: 3128.4927\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10716.7197, KL Div: 3220.4116\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10559.8643, KL Div: 3200.5637\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 10446.6885, KL Div: 3183.1921\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10560.1260, KL Div: 3268.5029\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 11065.2422, KL Div: 3145.5996\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10600.0176, KL Div: 3162.4875\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10908.7109, KL Div: 3246.3125\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10469.5625, KL Div: 3135.7808\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 11045.8887, KL Div: 3191.1448\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10464.0889, KL Div: 3196.2571\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 9894.0488, KL Div: 3208.8320\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10130.5996, KL Div: 3244.6323\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10835.6582, KL Div: 3130.1104\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10987.3457, KL Div: 3320.2788\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 11322.3701, KL Div: 3283.5273\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10377.9727, KL Div: 3212.8120\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10060.4873, KL Div: 3185.3315\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 11067.7510, KL Div: 3307.4043\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10969.4385, KL Div: 3160.8770\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 11066.2627, KL Div: 3230.3018\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 11047.5840, KL Div: 3264.0283\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10442.9121, KL Div: 3241.4282\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10341.0430, KL Div: 3162.7715\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10552.2188, KL Div: 3223.0076\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 10799.3389, KL Div: 3209.3110\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10448.8184, KL Div: 3199.4810\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10697.2988, KL Div: 3342.7275\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10419.8701, KL Div: 3180.7002\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 10762.6309, KL Div: 3363.6514\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10564.5303, KL Div: 3119.5393\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10781.2988, KL Div: 3231.2051\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10358.7227, KL Div: 3087.5627\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10429.6504, KL Div: 3213.8296\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10929.9561, KL Div: 3256.0107\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10713.3770, KL Div: 3249.0320\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 10544.5811, KL Div: 3085.3491\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10499.4609, KL Div: 3167.7014\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10001.0723, KL Div: 3162.7830\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 11188.4609, KL Div: 3313.0234\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10355.5898, KL Div: 3183.3425\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10411.6113, KL Div: 3201.6934\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10754.5518, KL Div: 3206.9338\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10073.8428, KL Div: 3107.3079\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10791.8906, KL Div: 3190.4822\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10540.8594, KL Div: 3194.1533\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10283.6611, KL Div: 3259.7373\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10392.5430, KL Div: 3198.2917\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10552.7959, KL Div: 3188.0823\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 10753.9404, KL Div: 3177.5576\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10772.1221, KL Div: 3324.7471\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10755.8906, KL Div: 3228.6028\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10708.2734, KL Div: 3194.4695\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10246.2627, KL Div: 3256.0645\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10422.5713, KL Div: 3186.0234\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10660.5615, KL Div: 3209.1821\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10493.7832, KL Div: 3190.2312\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10832.0576, KL Div: 3262.6196\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 10880.0781, KL Div: 3254.0879\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10479.8379, KL Div: 3205.3540\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10809.9570, KL Div: 3308.6045\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10761.4922, KL Div: 3246.5869\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 10954.3887, KL Div: 3220.9543\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10295.1309, KL Div: 3102.6641\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10510.6621, KL Div: 3191.3674\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10724.9746, KL Div: 3259.6558\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10780.0156, KL Div: 3184.3943\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10441.7373, KL Div: 3280.7764\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10317.1230, KL Div: 3306.2266\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10930.3848, KL Div: 3216.2322\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10015.2461, KL Div: 3246.6199\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10917.2188, KL Div: 3257.7881\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10293.0732, KL Div: 3044.3276\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10547.6826, KL Div: 3334.0186\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10485.0938, KL Div: 3231.0518\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 11083.3115, KL Div: 3282.2075\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 10601.3438, KL Div: 3217.6106\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10226.4336, KL Div: 3187.3484\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10307.1084, KL Div: 3238.2759\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10901.2832, KL Div: 3327.6167\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10788.7148, KL Div: 3116.3137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/15], Step [150/469], Reconst Loss: 10581.7822, KL Div: 3277.4067\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10696.2998, KL Div: 3176.2520\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10841.8955, KL Div: 3247.9673\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10614.6348, KL Div: 3285.1055\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10458.0625, KL Div: 3225.2378\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10663.6475, KL Div: 3250.8474\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10759.5781, KL Div: 3276.9731\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10547.7236, KL Div: 3295.5410\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10610.0605, KL Div: 3211.9624\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10583.4365, KL Div: 3265.1924\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10705.7217, KL Div: 3163.0298\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10623.8379, KL Div: 3358.5610\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10312.5693, KL Div: 3161.5137\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10444.0400, KL Div: 3165.5718\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 10099.4326, KL Div: 3248.6179\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10612.4678, KL Div: 3180.7617\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10283.4502, KL Div: 3225.3352\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10057.6016, KL Div: 3188.7119\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10341.0283, KL Div: 3223.8789\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10179.2676, KL Div: 3206.8276\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 11048.9932, KL Div: 3176.0649\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10400.2842, KL Div: 3202.7422\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10922.6289, KL Div: 3245.9937\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10576.9893, KL Div: 3237.8232\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10845.8770, KL Div: 3199.1914\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10902.6699, KL Div: 3428.0059\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10591.4141, KL Div: 3156.0620\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10764.4746, KL Div: 3341.7402\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10876.7314, KL Div: 3232.7981\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10591.5479, KL Div: 3188.0415\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10418.1240, KL Div: 3221.2761\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10261.2080, KL Div: 3173.7441\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10894.3730, KL Div: 3402.1621\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10425.1035, KL Div: 3205.1462\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10454.7930, KL Div: 3273.3464\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10478.6689, KL Div: 3297.1562\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10187.3984, KL Div: 3183.1382\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10748.8633, KL Div: 3163.3638\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10274.0664, KL Div: 3250.4846\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10482.1172, KL Div: 3132.6279\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 10509.6904, KL Div: 3225.4824\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10744.5859, KL Div: 3223.2759\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10316.1650, KL Div: 3248.4688\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10271.5898, KL Div: 3246.0737\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 9899.7969, KL Div: 3170.8354\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10275.5859, KL Div: 3111.0867\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 9736.1729, KL Div: 3139.5217\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10740.6943, KL Div: 3237.7209\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10713.4268, KL Div: 3278.6221\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10796.1133, KL Div: 3321.2593\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10750.8994, KL Div: 3214.9189\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10741.3164, KL Div: 3093.7766\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10144.7764, KL Div: 3185.0991\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10453.0576, KL Div: 3302.4673\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10681.3125, KL Div: 3270.1855\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10564.9893, KL Div: 3306.9919\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10604.7344, KL Div: 3193.2163\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10355.0752, KL Div: 3276.7271\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10074.8223, KL Div: 3262.8853\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10444.4180, KL Div: 3218.5298\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10312.8555, KL Div: 3314.6370\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10141.6670, KL Div: 3089.5642\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10841.9395, KL Div: 3323.6782\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10913.3750, KL Div: 3175.0034\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 11034.2256, KL Div: 3350.0151\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10300.5293, KL Div: 3241.2578\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10336.5156, KL Div: 3144.2571\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10770.5674, KL Div: 3262.1431\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10329.0674, KL Div: 3228.5571\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 9836.9170, KL Div: 3156.9104\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10878.2100, KL Div: 3315.4875\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 9765.8193, KL Div: 3239.8530\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10759.0781, KL Div: 3208.6279\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10406.8154, KL Div: 3151.4734\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10624.4922, KL Div: 3235.7380\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 10522.3457, KL Div: 3287.5349\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10558.3887, KL Div: 3202.1489\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10091.1924, KL Div: 3281.1487\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10474.1738, KL Div: 3294.4756\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10326.0254, KL Div: 3269.5688\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10555.1113, KL Div: 3228.1196\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10175.7002, KL Div: 3195.4287\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10212.2021, KL Div: 3099.9243\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10061.5859, KL Div: 3242.4595\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 10347.0469, KL Div: 3318.0212\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 10655.5576, KL Div: 3195.7212\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10351.8018, KL Div: 3115.5393\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10004.8721, KL Div: 3255.9016\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10442.2227, KL Div: 3258.4087\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 9993.5186, KL Div: 3250.7566\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10388.2480, KL Div: 3247.5210\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 10508.6826, KL Div: 3268.3496\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 10436.0352, KL Div: 3256.7407\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10215.3750, KL Div: 3252.1245\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10918.6455, KL Div: 3304.2402\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10084.3496, KL Div: 3169.6592\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10627.0088, KL Div: 3349.2666\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10308.5020, KL Div: 3226.5283\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10471.6973, KL Div: 3217.3853\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10312.8955, KL Div: 3286.0630\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10630.3887, KL Div: 3246.1553\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10363.3496, KL Div: 3254.6992\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10410.6729, KL Div: 3216.9487\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10481.8496, KL Div: 3220.2603\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 9869.2441, KL Div: 3116.7559\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10400.8154, KL Div: 3183.6504\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10631.9346, KL Div: 3176.0925\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10687.8838, KL Div: 3213.4094\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10508.1475, KL Div: 3405.8477\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10705.5605, KL Div: 3332.3838\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10524.3965, KL Div: 3283.0181\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10285.8018, KL Div: 3303.3936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/15], Step [350/469], Reconst Loss: 9753.1230, KL Div: 3118.3948\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10843.2363, KL Div: 3350.0386\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 10069.0068, KL Div: 3288.1152\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10314.9043, KL Div: 3176.8750\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 10388.3965, KL Div: 3238.1863\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10685.2920, KL Div: 3280.2310\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10286.0938, KL Div: 3290.4988\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10190.5059, KL Div: 3300.4453\n",
      "Epoch[10/15], Step [430/469], Reconst Loss: 9976.7441, KL Div: 3155.2769\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10132.3604, KL Div: 3182.5500\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10496.7734, KL Div: 3255.4468\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10102.9082, KL Div: 3291.2695\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10224.4102, KL Div: 3300.2705\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10244.6924, KL Div: 3223.8223\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10106.4902, KL Div: 3170.0427\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10336.3506, KL Div: 3348.6377\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10452.2803, KL Div: 3311.1160\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10476.4746, KL Div: 3383.3601\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10165.4932, KL Div: 3239.0537\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 9968.1357, KL Div: 3218.2371\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 9881.3457, KL Div: 3279.0298\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10513.2910, KL Div: 3287.2192\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 10297.0176, KL Div: 3258.2754\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10538.7432, KL Div: 3229.4304\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10241.3242, KL Div: 3269.5576\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 10925.4365, KL Div: 3278.1567\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 9990.8613, KL Div: 3231.0205\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10750.6719, KL Div: 3318.0947\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10390.0596, KL Div: 3228.2761\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10886.2529, KL Div: 3343.0901\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10433.1270, KL Div: 3133.3018\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10309.7510, KL Div: 3323.1313\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10467.0654, KL Div: 3218.3452\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10549.7666, KL Div: 3284.1775\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10495.1172, KL Div: 3161.1797\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10748.2266, KL Div: 3369.3335\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10407.0996, KL Div: 3249.8018\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 9929.8789, KL Div: 3204.2051\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10241.3184, KL Div: 3254.3169\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10524.6787, KL Div: 3189.9707\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10133.5244, KL Div: 3265.1423\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 10168.0811, KL Div: 3176.2834\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 10414.7520, KL Div: 3228.3472\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 9855.8174, KL Div: 3152.7175\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 10110.8457, KL Div: 3240.8611\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10431.2842, KL Div: 3186.2729\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10166.8242, KL Div: 3340.4546\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10618.4658, KL Div: 3317.1086\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10343.9141, KL Div: 3177.2017\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10265.7617, KL Div: 3310.3528\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10469.2314, KL Div: 3273.6997\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10185.1191, KL Div: 3275.0693\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 9999.4688, KL Div: 3170.3970\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10501.0410, KL Div: 3260.3262\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10388.3672, KL Div: 3341.3040\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 10703.1582, KL Div: 3295.8325\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 9687.3154, KL Div: 3037.4966\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 9645.5674, KL Div: 3059.5808\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10303.7412, KL Div: 3166.3499\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10065.4912, KL Div: 3306.8218\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10095.9248, KL Div: 3234.2610\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 10009.6221, KL Div: 3233.7881\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 9923.1953, KL Div: 3215.4814\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 10043.0986, KL Div: 3109.1589\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10392.0879, KL Div: 3368.1113\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10323.5059, KL Div: 3238.6860\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10622.2803, KL Div: 3276.9683\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10651.1465, KL Div: 3314.2136\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10452.1426, KL Div: 3174.9932\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10211.9883, KL Div: 3174.7126\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 10312.9209, KL Div: 3248.2493\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 9786.5586, KL Div: 3234.4316\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 10012.2725, KL Div: 3149.6074\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 9911.1816, KL Div: 3220.8660\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10587.9727, KL Div: 3222.8047\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10557.5684, KL Div: 3383.5039\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10239.5332, KL Div: 3154.4316\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10368.1211, KL Div: 3200.8962\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10236.5479, KL Div: 3361.0442\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 10394.1836, KL Div: 3226.8362\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 9989.2666, KL Div: 3167.5247\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 10758.1270, KL Div: 3246.5537\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 9884.5508, KL Div: 3223.5718\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10218.6875, KL Div: 3202.6816\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10685.7939, KL Div: 3381.7432\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10382.6943, KL Div: 3236.7566\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10272.9307, KL Div: 3321.3237\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10543.8691, KL Div: 3176.0127\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 10179.6387, KL Div: 3301.9077\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10328.1592, KL Div: 3190.5151\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10369.4023, KL Div: 3299.0449\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10196.7891, KL Div: 3283.0527\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10240.5283, KL Div: 3151.4709\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10411.7656, KL Div: 3286.4316\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10887.0000, KL Div: 3333.8757\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10523.5010, KL Div: 3236.9014\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10303.2686, KL Div: 3322.0952\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10345.0078, KL Div: 3313.2375\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10241.5391, KL Div: 3193.4614\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 10659.8994, KL Div: 3365.2319\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 10409.0664, KL Div: 3323.3477\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10706.7363, KL Div: 3329.3022\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10355.5605, KL Div: 3288.1211\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 9896.9355, KL Div: 3197.9614\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10746.7197, KL Div: 3243.7825\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10036.9375, KL Div: 3198.4502\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10428.0352, KL Div: 3391.5798\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 9930.0830, KL Div: 3201.3906\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10420.4590, KL Div: 3285.3906\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10129.0830, KL Div: 3257.3894\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 9989.1152, KL Div: 3283.9951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13/15], Step [80/469], Reconst Loss: 10517.2100, KL Div: 3236.8618\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10518.3818, KL Div: 3371.1323\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 9966.4336, KL Div: 3212.1768\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10587.7227, KL Div: 3331.4158\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10077.3799, KL Div: 3224.2639\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10293.9961, KL Div: 3272.3022\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10057.9736, KL Div: 3231.3379\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 10035.7061, KL Div: 3244.3662\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10268.5605, KL Div: 3288.2234\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 10341.8672, KL Div: 3279.3843\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10165.0889, KL Div: 3214.9832\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 10008.9863, KL Div: 3257.1475\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10407.5166, KL Div: 3310.4790\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 10493.1162, KL Div: 3299.4204\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 10013.0547, KL Div: 3233.9067\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10442.4150, KL Div: 3321.1904\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 10596.5879, KL Div: 3282.9353\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10086.3906, KL Div: 3340.5894\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10008.3643, KL Div: 3174.7280\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 9679.9600, KL Div: 3176.2434\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10384.4883, KL Div: 3375.8218\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10393.9033, KL Div: 3144.7041\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 9892.8633, KL Div: 3303.4290\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10371.1660, KL Div: 3266.2791\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10466.2773, KL Div: 3305.5979\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10482.5029, KL Div: 3181.7227\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10528.0654, KL Div: 3232.1831\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10281.7979, KL Div: 3350.9829\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 9572.4219, KL Div: 3112.6729\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 9991.4727, KL Div: 3192.1235\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10236.1357, KL Div: 3326.6074\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10596.2959, KL Div: 3136.1533\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 9791.0820, KL Div: 3298.3315\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 9959.7451, KL Div: 3158.8521\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 10555.1074, KL Div: 3287.8672\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10273.9287, KL Div: 3344.0576\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10368.3682, KL Div: 3228.6885\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10886.6846, KL Div: 3321.8923\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10250.1270, KL Div: 3296.5935\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 10346.1260, KL Div: 3250.9197\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 9750.2441, KL Div: 3218.0391\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10328.2607, KL Div: 3315.9971\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10612.4424, KL Div: 3292.0664\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 10529.3018, KL Div: 3330.4890\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10410.8789, KL Div: 3255.7805\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10031.0986, KL Div: 3165.4072\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 9796.2344, KL Div: 3269.9504\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10486.1016, KL Div: 3296.0669\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 10408.8730, KL Div: 3296.5190\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10292.5391, KL Div: 3332.7637\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10112.5186, KL Div: 3158.0884\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 10172.1328, KL Div: 3227.4658\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 10230.9414, KL Div: 3310.8032\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 10411.5283, KL Div: 3299.3535\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10198.2246, KL Div: 3168.3774\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 10143.1221, KL Div: 3152.4202\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 10136.9307, KL Div: 3362.8687\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 9839.6934, KL Div: 3228.9331\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 9857.3320, KL Div: 3304.4182\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 9825.9961, KL Div: 3137.6143\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 9768.5322, KL Div: 3255.5273\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 10217.2129, KL Div: 3259.6934\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 9693.4697, KL Div: 3142.6743\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 9854.2871, KL Div: 3256.1873\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 9879.3223, KL Div: 3094.4600\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10447.8633, KL Div: 3307.9048\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 10492.9277, KL Div: 3188.1667\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 10408.2070, KL Div: 3265.7634\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 9885.6973, KL Div: 3300.7029\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 9624.8389, KL Div: 3261.6143\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10145.8818, KL Div: 3264.7029\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 10363.4766, KL Div: 3329.7236\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 9967.2520, KL Div: 3213.0974\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 9949.9873, KL Div: 3231.2612\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 9764.6289, KL Div: 3164.7036\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10132.5908, KL Div: 3214.0308\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 9694.8057, KL Div: 3166.0698\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 10579.9082, KL Div: 3320.6274\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10188.8027, KL Div: 3252.3765\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10743.2910, KL Div: 3392.2812\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10260.7852, KL Div: 3150.6646\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 10806.7148, KL Div: 3309.4636\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 9918.2959, KL Div: 3334.5713\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 9782.4521, KL Div: 3125.6123\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10139.7422, KL Div: 3245.4548\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 10311.8291, KL Div: 3301.4194\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 9729.1719, KL Div: 3231.5085\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10642.8359, KL Div: 3308.2996\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 9834.9990, KL Div: 3293.2168\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 9985.0000, KL Div: 3165.4785\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 10017.2207, KL Div: 3211.7078\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10476.4258, KL Div: 3309.2341\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10046.0479, KL Div: 3250.8877\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 9885.0264, KL Div: 3205.0479\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 10462.5273, KL Div: 3306.7246\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10534.4551, KL Div: 3407.2163\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 10126.9922, KL Div: 3202.6191\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 10650.6680, KL Div: 3271.6875\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10179.9453, KL Div: 3420.1045\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10547.7686, KL Div: 3313.1375\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 9731.0029, KL Div: 3150.6318\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 9739.4648, KL Div: 3234.0835\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10334.4775, KL Div: 3211.8638\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 10223.8994, KL Div: 3334.5625\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 9872.7715, KL Div: 3176.3962\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 10379.2754, KL Div: 3266.4707\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 10063.0000, KL Div: 3261.7034\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 9907.2100, KL Div: 3231.3643\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 10592.9355, KL Div: 3262.0337\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 10323.4404, KL Div: 3344.8799\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10406.6309, KL Div: 3364.7466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15/15], Step [270/469], Reconst Loss: 10070.1602, KL Div: 3202.6008\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 9670.2266, KL Div: 3101.6777\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 10122.2920, KL Div: 3314.1934\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10149.4854, KL Div: 3250.3789\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10218.1260, KL Div: 3171.2886\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 10129.1729, KL Div: 3312.7554\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 10249.3652, KL Div: 3352.6230\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 10151.9746, KL Div: 3166.7422\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 9736.6914, KL Div: 3234.3789\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 9945.6211, KL Div: 3223.7300\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 10025.1953, KL Div: 3223.1973\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10390.7354, KL Div: 3240.0039\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 10423.6377, KL Div: 3269.2993\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10027.5068, KL Div: 3111.2773\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 10307.1924, KL Div: 3328.3364\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 10149.3086, KL Div: 3222.3455\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 10118.1885, KL Div: 3230.8779\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 10309.9268, KL Div: 3334.2915\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10251.6689, KL Div: 3267.4099\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 9674.7607, KL Div: 3314.7195\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
